{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31371588a60979c7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Zero Shot Learning and Natural Language Inference for Text Classification - Model Predicting\n",
    "\n",
    "**Author:** Airc Miao\n",
    "**Date:** 2024-02-17\n",
    "**Rule:**\n",
    "1. If any value is empty, return \"low\"\n",
    "2. Otherwise, use the model to predict the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8509e83b864cf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T03:00:33.838730Z",
     "start_time": "2024-02-18T03:00:33.836531Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ca967aed61d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Give an example here. Correct output is \"medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b414af75efef3db9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:58:57.867679Z",
     "start_time": "2024-02-18T02:58:57.865141Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "general_cap_classification = \"UNPROFESSIONAL CONDUCT\"\n",
    "\n",
    "summary = \"\"\"According to the complainant, on 11-6-22 at 8:30 PM, while in the confines of the 24th District, they were treated unprofessionally by an unknown officer. Police stopped them. The complainant states that the officer attempted to hit them with their patrol car, after accusing them of trying to go around other vehicles. The complainant states that the officer disrespected them, went over their loud speaker and made an inappropriate comment.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a929dd9deff832eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:58:57.971752Z",
     "start_time": "2024-02-18T02:58:57.969308Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Trim texts\n",
    "general_cap_classification = general_cap_classification.strip()\n",
    "summary = summary.strip()\n",
    "\n",
    "# if any is empty, return \"low\"\n",
    "if general_cap_classification == '' or summary == '':\n",
    "    print('low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc30334b13bae5b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:58:58.258045Z",
     "start_time": "2024-02-18T02:58:58.252281Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cleanAndTokenizeText(txt):\n",
    "    # Remove \"According to the complainant,\"\n",
    "    txt = txt.replace('According to the complainant,', '')\n",
    "\n",
    "    # Remove dates\n",
    "    date_pattern= r'(?:\\,\\s)*(?:on\\s)*\\d+-\\d+-\\d+[\\s]*[\\,]*'\n",
    "    txt = re.sub(date_pattern, '', txt, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove time\n",
    "    time_pattern= r'(at)?\\s?\\d+:\\d+\\s?(AM|PM)?\\,?\\s?'\n",
    "    txt = re.sub(time_pattern, '', txt, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove locations of patter of (the\\s)?\\d+\\w+\\s?District\n",
    "    location_pattern= r'(the\\s)?\\d+\\w+\\s?District'\n",
    "    txt = re.sub(location_pattern, '', txt, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove \"While in the confines of ,\"\n",
    "    txt = txt.replace(\"While in the confines of ,\", '')\n",
    "\n",
    "    words = nltk.tokenize.word_tokenize(txt)\n",
    "\n",
    "    # make all lower case\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    #stopwords\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word.lower() not in stopwords]\n",
    "\n",
    "    # Remove punctuation\n",
    "    words = [word for word in words if word.isalnum()]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Remove numbers\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "\n",
    "    # remove only one-letter words\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "\n",
    "    # return text of words\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61bce18e18a73e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T03:02:42.720042Z",
     "start_time": "2024-02-18T03:02:42.601695Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with text as column which combies the general_cap_classification and summary\n",
    "df = pd.DataFrame({'text': [general_cap_classification + '. ' + summary]})\n",
    "\n",
    "# Clean text\n",
    "df['text'] = df['text'].apply(cleanAndTokenizeText)\n",
    "\n",
    "# CountVectorizer\n",
    "count_vectorizer = joblib.load('vectorizer.pkl')\n",
    "\n",
    "# Transform the text\n",
    "X = count_vectorizer.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4c8864b8cd59222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T03:02:51.242397Z",
     "start_time": "2024-02-18T03:02:51.234166Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medium'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = joblib.load('model_lr_cv.pkl')\n",
    "\n",
    "\n",
    "# Predict the label\n",
    "label = model.predict(X )[0]\n",
    "\n",
    "# Return the label\n",
    "label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dd8345aa91ac33",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
